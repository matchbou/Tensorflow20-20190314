{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST Estimator to TPUEstimator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matchbou/Tensorflow20-20190314/blob/master/MNIST_Estimator_to_TPUEstimator-FinRun-Error-Due-To-Gcp-Unset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "xqLjB2cy5S7m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## MNIST Estimator to TPUEstimator\n",
        "\n",
        "This notebook will show you how to port an Estimator model to TPUEstimator.\n",
        "\n",
        "All the lines that had to be changed in the porting are marked with a \"TPU REFACTORING\" comment.\n",
        "\n",
        "You do the porting only once. TPUEstimator then works on both TPU and GPU with the use_tpu=False flag."
      ]
    },
    {
      "metadata": {
        "id": "qpiJj8ym0v0-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ]
    },
    {
      "metadata": {
        "id": "AoilhmYe1b5t",
        "colab_type": "code",
        "outputId": "4a0a35f2-c89c-4232-e54c-1c1ff61ddf60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os, re, math, json, shutil, pprint, datetime\n",
        "import PIL.Image, PIL.ImageFont, PIL.ImageDraw  # \"pip3 install Pillow\" or \"pip install Pillow\" if needed\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.python.platform import tf_logging\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aBDGQWkbLGvh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Parameters"
      ]
    },
    {
      "metadata": {
        "id": "_V_VbLELLJCS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "3726c64c-57df-4d71-c64c-da935ca71cca"
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32 #@param {type:\"integer\"}\n",
        "BUCKET = 'gs://' #@param {type:\"string\"}\n",
        "\n",
        "assert re.search(r'gs://.+', BUCKET), 'You need a GCS bucket for your Tensorboard logs. Head to http://console.cloud.google.com/storage and create one.'\n",
        "\n",
        "training_images_file   = 'gs://mnist-public/train-images-idx3-ubyte'\n",
        "training_labels_file   = 'gs://mnist-public/train-labels-idx1-ubyte'\n",
        "validation_images_file = 'gs://mnist-public/t10k-images-idx3-ubyte'\n",
        "validation_labels_file = 'gs://mnist-public/t10k-labels-idx1-ubyte'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-43eed5e8710e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mBUCKET\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gs://'\u001b[0m \u001b[0;31m#@param {type:\"string\"}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'gs://.+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBUCKET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'You need a GCS bucket for your Tensorboard logs. Head to http://console.cloud.google.com/storage and create one.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtraining_images_file\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0;34m'gs://mnist-public/train-images-idx3-ubyte'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: You need a GCS bucket for your Tensorboard logs. Head to http://console.cloud.google.com/storage and create one."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "qhdz68Xm3Z4Z",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title visualization utilities [RUN ME]\n",
        "\"\"\"\n",
        "This cell contains helper functions used for visualization\n",
        "and downloads only. You can skip reading it. There is very\n",
        "little useful Keras/Tensorflow code here.\n",
        "\"\"\"\n",
        "\n",
        "# Matplotlib config\n",
        "plt.rc('image', cmap='gray_r')\n",
        "plt.rc('grid', linewidth=0)\n",
        "plt.rc('xtick', top=False, bottom=False, labelsize='large')\n",
        "plt.rc('ytick', left=False, right=False, labelsize='large')\n",
        "plt.rc('axes', facecolor='F8F8F8', titlesize=\"large\", edgecolor='white')\n",
        "plt.rc('text', color='a8151a')\n",
        "plt.rc('figure', facecolor='F0F0F0')# Matplotlib fonts\n",
        "MATPLOTLIB_FONT_DIR = os.path.join(os.path.dirname(plt.__file__), \"mpl-data/fonts/ttf\")\n",
        "\n",
        "# pull a batch from the datasets. This code is not very nice, it gets much better in eager mode (TODO)\n",
        "def dataset_to_numpy_util(training_dataset, validation_dataset, N):\n",
        "  \n",
        "  # get one batch from each: 10000 validation digits, N training digits\n",
        "  unbatched_train_ds = training_dataset.apply(tf.data.experimental.unbatch())\n",
        "  v_images, v_labels = validation_dataset.make_one_shot_iterator().get_next()\n",
        "  t_images, t_labels = unbatched_train_ds.batch(N).make_one_shot_iterator().get_next()\n",
        "  \n",
        "  # Run once, get one batch. Session.run returns numpy results\n",
        "  with tf.Session() as ses:\n",
        "    (validation_digits, validation_labels,\n",
        "     training_digits, training_labels) = ses.run([v_images, v_labels, t_images, t_labels])\n",
        "  \n",
        "  # these were one-hot encoded in the dataset\n",
        "  validation_labels = np.argmax(validation_labels, axis=1)\n",
        "  training_labels = np.argmax(training_labels, axis=1)\n",
        "  \n",
        "  return (training_digits, training_labels,\n",
        "          validation_digits, validation_labels)\n",
        "\n",
        "# create digits from local fonts for testing\n",
        "def create_digits_from_local_fonts(n):\n",
        "  font_labels = []\n",
        "  img = PIL.Image.new('LA', (28*n, 28), color = (0,255)) # format 'LA': black in channel 0, alpha in channel 1\n",
        "  font1 = PIL.ImageFont.truetype(os.path.join(MATPLOTLIB_FONT_DIR, 'DejaVuSansMono-Oblique.ttf'), 25)\n",
        "  font2 = PIL.ImageFont.truetype(os.path.join(MATPLOTLIB_FONT_DIR, 'STIXGeneral.ttf'), 25)\n",
        "  d = PIL.ImageDraw.Draw(img)\n",
        "  for i in range(n):\n",
        "    font_labels.append(i%10)\n",
        "    d.text((7+i*28,0 if i<10 else -4), str(i%10), fill=(255,255), font=font1 if i<10 else font2)\n",
        "  font_digits = np.array(img.getdata(), np.float32)[:,0] / 255.0 # black in channel 0, alpha in channel 1 (discarded)\n",
        "  font_digits = np.reshape(np.stack(np.split(np.reshape(font_digits, [28, 28*n]), n, axis=1), axis=0), [n, 28*28])\n",
        "  return font_digits, font_labels\n",
        "\n",
        "# utility to display a row of digits with their predictions\n",
        "def display_digits(digits, predictions, labels, title, n):\n",
        "  plt.figure(figsize=(13,3))\n",
        "  digits = np.reshape(digits, [n, 28, 28])\n",
        "  digits = np.swapaxes(digits, 0, 1)\n",
        "  digits = np.reshape(digits, [28, 28*n])\n",
        "  plt.yticks([])\n",
        "  plt.xticks([28*x+14 for x in range(n)], predictions)\n",
        "  for i,t in enumerate(plt.gca().xaxis.get_ticklabels()):\n",
        "    if predictions[i] != labels[i]: t.set_color('red') # bad predictions in red\n",
        "  plt.imshow(digits)\n",
        "  plt.grid(None)\n",
        "  plt.title(title)\n",
        "  \n",
        "# utility to display multiple rows of digits, sorted by unrecognized/recognized status\n",
        "def display_top_unrecognized(digits, predictions, labels, n, lines):\n",
        "  idx = np.argsort(predictions==labels) # sort order: unrecognized first\n",
        "  for i in range(lines):\n",
        "    display_digits(digits[idx][i*n:(i+1)*n], predictions[idx][i*n:(i+1)*n], labels[idx][i*n:(i+1)*n],\n",
        "                   \"{} sample validation digits out of {} with bad predictions in red and sorted first\".format(n*lines, len(digits)) if i==0 else \"\", n)\n",
        "    \n",
        "# utility to display training and validation curves\n",
        "def display_training_curves(training, validation, title, subplot):\n",
        "  if subplot%10==1: # set up the subplots on the first call\n",
        "    plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n",
        "    plt.tight_layout()\n",
        "  ax = plt.subplot(subplot)\n",
        "  ax.grid(linewidth=1, color='white')\n",
        "  ax.plot(training)\n",
        "  ax.plot(validation)\n",
        "  ax.set_title('model '+ title)\n",
        "  ax.set_ylabel(title)\n",
        "  ax.set_xlabel('epoch')\n",
        "  ax.legend(['train', 'valid.'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lzd6Qi464PsA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Colab-only auth for this notebook and the TPU"
      ]
    },
    {
      "metadata": {
        "id": "MPx0nvyUnvgT",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "c043c00c-a46c-4dad-c41d-96e921cb788e"
      },
      "cell_type": "code",
      "source": [
        "IS_COLAB_BACKEND = 'COLAB_GPU' in os.environ  # this is always set on Colab, the value is 0 or 1 depending on GPU presence\n",
        "if IS_COLAB_BACKEND:\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user() # Authenticates the backend and also the TPU using your credentials so that they can access your private GCS buckets"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bLZKp8bWZdmh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### TPU detection"
      ]
    },
    {
      "metadata": {
        "id": "qQpdD_DSZjNY",
        "colab_type": "code",
        "outputId": "3d463466-01dc-4146-8d0f-73b8d13bd128",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#TPU REFACTORING: detect the TPU\n",
        "try: # TPU detection\n",
        "  tpu = tf.contrib.cluster_resolver.TPUClusterResolver() # Picks up a connected TPU on Google's Colab, ML Engine, Kubernetes and Deep Learning VMs accessed through the 'ctpu up' utility\n",
        "  #tpu = tf.contrib.cluster_resolver.TPUClusterResolver('MY_TPU_NAME') # If auto-detection does not work, you can pass the name of the TPU explicitly (tip: on a VM created with \"ctpu up\" the TPU has the same name as the VM)\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "  USE_TPU = True\n",
        "except ValueError:\n",
        "  tpu = None\n",
        "  print(\"Running on GPU or CPU\")\n",
        "  USE_TPU = False"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  ['10.94.251.122:8470']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Lz1Zknfk4qCx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### tf.data.Dataset: parse files and prepare training and validation datasets\n",
        "Please read the [best practices for building](https://www.tensorflow.org/guide/performance/datasets) input pipelines with tf.data.Dataset"
      ]
    },
    {
      "metadata": {
        "id": "ZE8dgyPC1_6m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "3e6d882f-63b4-46ef-eb50-1d1bd5163fca"
      },
      "cell_type": "code",
      "source": [
        "def read_label(tf_bytestring):\n",
        "    label = tf.decode_raw(tf_bytestring, tf.uint8)\n",
        "    label = tf.reshape(label, [])\n",
        "    label = tf.one_hot(label, 10)\n",
        "    return label\n",
        "  \n",
        "def read_image(tf_bytestring):\n",
        "    image = tf.decode_raw(tf_bytestring, tf.uint8)\n",
        "    image = tf.cast(image, tf.float32)/256.0\n",
        "    image = tf.reshape(image, [28*28])\n",
        "    return image\n",
        "  \n",
        "def load_dataset(image_file, label_file):\n",
        "    imagedataset = tf.data.FixedLengthRecordDataset(image_file, 28*28, header_bytes=16)\n",
        "    imagedataset = imagedataset.map(read_image, num_parallel_calls=16)\n",
        "    labelsdataset = tf.data.FixedLengthRecordDataset(label_file, 1, header_bytes=8)\n",
        "    labelsdataset = labelsdataset.map(read_label, num_parallel_calls=16)\n",
        "    dataset = tf.data.Dataset.zip((imagedataset, labelsdataset))\n",
        "    return dataset \n",
        "  \n",
        "def get_training_dataset(image_file, label_file, batch_size):\n",
        "    dataset = load_dataset(image_file, label_file)\n",
        "    dataset = dataset.cache()  # this small dataset can be entirely cached in RAM, for TPU this is important to get good performance from such a small dataset\n",
        "    dataset = dataset.shuffle(5000, reshuffle_each_iteration=True)\n",
        "    dataset = dataset.repeat() # Mandatory for TPU for now\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True) # drop_remainder is important on TPU, batch size must be fixed\n",
        "    dataset = dataset.prefetch(-1)  # prefetch next batch while training  (-1: autotune prefetch buffer size)\n",
        "    return dataset\n",
        "\n",
        "#TPU REFACTORING: training and eval batch sizes must be the same: passing  batch_size parameter here too\n",
        "# def get_validation_dataset(image_file, label_file):\n",
        "def get_validation_dataset(image_file, label_file, batch_size):\n",
        "    dataset = load_dataset(image_file, label_file)\n",
        "    dataset = dataset.cache() # this small dataset can be entirely cached in RAM, for TPU this is important to get good performance from such a small dataset\n",
        "    #TPU REFACTORING: training and eval batch sizes must be the same: passing  batch_size parameter here too\n",
        "    # dataset = dataset.batch(10000, drop_remainder=True) # 10000 items in eval dataset, all in one batch\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "    dataset = dataset.repeat() # Mandatory for TPU for now\n",
        "    return dataset\n",
        "\n",
        "# instantiate the datasets\n",
        "training_dataset = get_training_dataset(training_images_file, training_labels_file, BATCH_SIZE)\n",
        "validation_dataset = get_validation_dataset(validation_images_file, validation_labels_file, 10000)\n",
        "\n",
        "# For TPU, we will need a function that returns the dataset\n",
        "\n",
        "# TPU REFACTORING: input_fn's must have a params argument though which TPUEstimator passes params['batch_size']\n",
        "# training_input_fn = lambda: get_training_dataset(training_images_file, training_labels_file, BATCH_SIZE)\n",
        "# validation_input_fn = lambda: get_validation_dataset(validation_images_file, validation_labels_file)\n",
        "training_input_fn = lambda params: get_training_dataset(training_images_file, training_labels_file, params['batch_size'])\n",
        "validation_input_fn = lambda params: get_validation_dataset(validation_images_file, validation_labels_file, params['batch_size'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6f86a77ca3c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# instantiate the datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mtraining_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_training_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mvalidation_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_validation_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_images_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'training_images_file' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "_fXo6GuvL3EB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Let's have a look at the data"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "db911531-3e7d-4e9b-8d2e-921dc0397db0",
        "id": "DaWNgUPKLz_9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "cell_type": "code",
      "source": [
        "N = 24\n",
        "(training_digits, training_labels,\n",
        " validation_digits, validation_labels) = dataset_to_numpy_util(training_dataset, validation_dataset, N)\n",
        "display_digits(training_digits, training_labels, training_labels, \"training digits and their labels\", N)\n",
        "display_digits(validation_digits[:N], validation_labels[:N], validation_labels[:N], \"validation digits and their labels\", N)\n",
        "font_digits, font_labels = create_digits_from_local_fonts(N)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-1fc95db3da02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m (training_digits, training_labels,\n\u001b[0;32m----> 3\u001b[0;31m  validation_digits, validation_labels) = dataset_to_numpy_util(training_dataset, validation_dataset, N)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdisplay_digits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_digits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"training digits and their labels\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdisplay_digits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_digits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"validation digits and their labels\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'training_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "KIc0oqiD40HC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Estimator model\n",
        "If you are not sure what cross-entropy, dropout, softmax or batch-normalization mean, head here for a crash-course: [Tensorflow and deep learning without a PhD](https://github.com/GoogleCloudPlatform/tensorflow-without-a-phd/#featured-code-sample)"
      ]
    },
    {
      "metadata": {
        "id": "56y8UNFQIVwj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This model trains to 99.4% sometimes 99.5% accuracy in 10 epochs\n",
        "\n",
        "# TPU REFACTORING: model_fn must have a params argument. TPUEstimator passes batch_size and use_tpu into it\n",
        "#def model_fn(features, labels, mode):\n",
        "def model_fn(features, labels, mode, params):\n",
        "\n",
        "  is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "  x = features\n",
        "  y = tf.reshape(x, [-1, 28, 28, 1])\n",
        "\n",
        "  y = tf.layers.Conv2D(filters=6, kernel_size=3, padding='same', use_bias=False)(y) # no bias necessary before batch norm\n",
        "  y = tf.layers.BatchNormalization(scale=False, center=True)(y, training=is_training) # no batch norm scaling necessary before \"relu\"\n",
        "  y = tf.nn.relu(y) # activation after batch norm\n",
        "\n",
        "  y = tf.layers.Conv2D(filters=12, kernel_size=6, padding='same', use_bias=False, strides=2)(y)\n",
        "  y = tf.layers.BatchNormalization(scale=False, center=True)(y, training=is_training)\n",
        "  y = tf.nn.relu(y)\n",
        "\n",
        "  y = tf.layers.Conv2D(filters=24, kernel_size=6, padding='same', use_bias=False, strides=2)(y)\n",
        "  y = tf.layers.BatchNormalization(scale=False, center=True)(y, training=is_training)\n",
        "  y = tf.nn.relu(y)\n",
        "\n",
        "  y = tf.layers.Flatten()(y)\n",
        "  y = tf.layers.Dense(200, use_bias=False)(y)\n",
        "  y = tf.layers.BatchNormalization(scale=False, center=True)(y, training=is_training)\n",
        "  y = tf.nn.relu(y)\n",
        "  y = tf.layers.Dropout(0.5)(y, training=is_training)\n",
        "  \n",
        "  logits = tf.layers.Dense(10)(y)\n",
        "  predictions = tf.nn.softmax(logits)\n",
        "  classes = tf.math.argmax(predictions, axis=-1)\n",
        "  \n",
        "  if (mode != tf.estimator.ModeKeys.PREDICT):\n",
        "    loss = tf.losses.softmax_cross_entropy(labels, logits)\n",
        "\n",
        "    step = tf.train.get_or_create_global_step()\n",
        "    # TPU REFACTORING: step is now increased once per GLOBAL_BATCH_SIZE = 8*BATCH_SIZE. Must adjust learning rate schedule accordingly\n",
        "    # lr = 0.0001 + tf.train.exponential_decay(0.01, step, 2000, 1/math.e)\n",
        "    lr = 0.0001 + tf.train.exponential_decay(0.01, step, 2000//8, 1/math.e)\n",
        "    \n",
        "    # TPU REFACTORING: custom Tensorboard summaries do not work. Only default Estimator summaries will appear in Tensorboard.\n",
        "    # tf.summary.scalar(\"learn_rate\", lr)\n",
        "    \n",
        "    optimizer = tf.train.AdamOptimizer(lr)\n",
        "    # TPU REFACTORING: wrap the optimizer in a CrossShardOptimizer: this implements the multi-core training logic\n",
        "    if params['use_tpu']:\n",
        "      optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)\n",
        "    \n",
        "    # little wrinkle: batch norm uses running averages which need updating after each batch. create_train_op does it, optimizer.minimize does not.\n",
        "    train_op = tf.contrib.training.create_train_op(loss, optimizer)\n",
        "    #train_op = optimizer.minimize(loss, tf.train.get_or_create_global_step())\n",
        "    \n",
        "    # TPU REFACTORING: a metrics_fn is needed for TPU\n",
        "    # metrics = {'accuracy': tf.metrics.accuracy(classes, tf.math.argmax(labels, axis=-1))}\n",
        "    metric_fn = lambda classes, labels: {'accuracy': tf.metrics.accuracy(classes, tf.math.argmax(labels, axis=-1))}\n",
        "    tpu_metrics = (metric_fn, [classes, labels])  # pair of metric_fn and its list of arguments, there can be multiple pairs in a list\n",
        "                                                  # metric_fn will run on CPU, not TPU: more operations are allowed\n",
        "  else:\n",
        "    loss = train_op = metrics = tpu_metrics = None  # None of these can be computed in prediction mode because labels are not available\n",
        "  \n",
        "  # TPU REFACTORING: EstimatorSpec => TPUEstimatorSpec\n",
        "  ## return tf.estimator.EstimatorSpec(\n",
        "  return tf.contrib.tpu.TPUEstimatorSpec(\n",
        "    mode=mode,\n",
        "    predictions={\"predictions\": predictions, \"classes\": classes},  # name these fields as you like\n",
        "    loss=loss,\n",
        "    train_op=train_op,\n",
        "    # TPU REFACTORING: a metrics_fn is needed for TPU, passed into the eval_metrics field instead of eval_metrics_ops\n",
        "    # eval_metric_ops=metrics\n",
        "    eval_metrics = tpu_metrics\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DeIxkrv9Wihg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Called once when the model is saved. This function produces a Tensorflow\n",
        "# graph of operations that will be prepended to your model graph. When\n",
        "# your model is deployed as a REST API, the API receives data in JSON format,\n",
        "# parses it into Tensors, then sends the tensors to the input graph generated by\n",
        "# this function. The graph can transform the data so it can be sent into your\n",
        "# model input_fn. You can do anything you want here as long as you do it with\n",
        "# tf.* functions that produce a graph of operations.\n",
        "def serving_input_fn():\n",
        "    # placeholder for the data received by the API (already parsed, no JSON decoding necessary,\n",
        "    # but the JSON must contain one or multiple 'image' key(s) with 28x28 greyscale images  as content.)\n",
        "    inputs = {\"serving_input\": tf.placeholder(tf.float32, [None, 28, 28])}  # the shape of this dict should match the shape of your JSON\n",
        "    features = inputs['serving_input']  # no transformation needed\n",
        "    return tf.estimator.export.TensorServingInputReceiver(features, inputs)  # features are the features needed by your model_fn\n",
        "    # Return a ServingInputReceiver if your features are a dictionary of Tensors, TensorServingInputReceiver if they are a straight Tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RxpRgF874-ix",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train and validate the model, this time on TPU"
      ]
    },
    {
      "metadata": {
        "id": "TTwH_P-ZJ_xx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "outputId": "cc96c803-a998-4aa4-bb91-2a7dc33ce817"
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "# TPU_REFACTORING: to use all 8 cores, increase the batch size by 8\n",
        "GLOBAL_BATCH_SIZE = BATCH_SIZE * 8\n",
        "\n",
        "# TPU_REFACTORING: TPUEstimator increments the step once per GLOBAL_BATCH_SIZE: must adjust epoch length accordingly\n",
        "# steps_per_epoch = 60000 // BATCH_SIZE  # 60,000 images in training dataset\n",
        "steps_per_epoch = 60000 // GLOBAL_BATCH_SIZE  # 60,000 images in training dataset\n",
        "\n",
        "MODEL_EXPORT_NAME = \"mnist\"  # name for exporting saved model\n",
        "\n",
        "# TPU_REFACTORING: the TPU will run multiple steps of training before reporting back\n",
        "TPU_ITERATIONS_PER_LOOP = steps_per_epoch # report back after each epoch\n",
        "\n",
        "tf_logging.set_verbosity(tf_logging.INFO)\n",
        "now = datetime.datetime.now()\n",
        "MODEL_DIR = BUCKET+\"/mnistjobs/job\" + \"-{}-{:02d}-{:02d}-{:02d}:{:02d}:{:02d}\".format(now.year, now.month, now.day, now.hour, now.minute, now.second)\n",
        "\n",
        "# TPU REFACTORING: the RunConfig has changed\n",
        "#training_config = tf.estimator.RunConfig(model_dir=MODEL_DIR, save_summary_steps=10, save_checkpoints_steps=steps_per_epoch, log_step_count_steps=steps_per_epoch/4)\n",
        "training_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu,\n",
        "    model_dir=MODEL_DIR,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(TPU_ITERATIONS_PER_LOOP))\n",
        "   \n",
        "# TPU_REFACTORING: exporters do not work yet. Must call export_savedmodel manually after training\n",
        "#export_latest = tf.estimator.LatestExporter(MODEL_EXPORT_NAME, serving_input_receiver_fn=serving_input_fn)\n",
        "    \n",
        "# TPU_REFACTORING: Estimator => TPUEstimator\n",
        "#estimator = tf.estimator.Estimator(model_fn=model_fn, config=training_config)\n",
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    model_fn=model_fn,\n",
        "    model_dir=MODEL_DIR,\n",
        "    # TPU_REFACTORING: training and eval batch size must be the same for now\n",
        "    train_batch_size=GLOBAL_BATCH_SIZE,\n",
        "    eval_batch_size=10000,  # 10000 digits in eval dataset\n",
        "    predict_batch_size=10000, # prediction on the entire eval dataset in the demo below\n",
        "    config=training_config,\n",
        "    use_tpu=USE_TPU,\n",
        "    # TPU REFACTORING: setting the kind of model export we want\n",
        "    export_to_tpu=False)  # we want an exported model for CPU/GPU inference because that is what is supported on ML Engine\n",
        "\n",
        "# TPU REFACTORING: train_and_evaluate does not work on TPU yet, TrainSpec not needed\n",
        "# train_spec = tf.estimator.TrainSpec(training_input_fn, max_steps=EPOCHS*steps_per_epoch)\n",
        "# TPU REFACTORING: train_and_evaluate does not work on TPU yet, EvalSpec not needed\n",
        "# eval_spec = tf.estimator.EvalSpec(validation_input_fn, steps=1, exporters=export_latest, throttle_secs=0) # no eval throttling: evaluates after each checkpoint\n",
        "\n",
        "# TPU REFACTORING: train_and_evaluate does not work on TPU yet, must train then eval manually\n",
        "# tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
        "estimator.train(training_input_fn, steps=steps_per_epoch*EPOCHS)\n",
        "estimator.evaluate(input_fn=validation_input_fn, steps=1)\n",
        "  \n",
        "# TPU REFACTORING: exporters do not work yet. Must call export_savedmodel manually after training\n",
        "estimator.export_savedmodel(os.path.join(MODEL_DIR, MODEL_EXPORT_NAME), serving_input_fn)\n",
        "tf_logging.set_verbosity(tf_logging.WARN)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x7ff5224330d0>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs:///mnistjobs/job-2019-03-20-07:31:47', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.94.251.122:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff52240bb70>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.94.251.122:8470', '_evaluation_master': 'grpc://10.94.251.122:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=234, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7ff5503f8a58>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-398017a6f986>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# TPU REFACTORING: train_and_evaluate does not work on TPU yet, must train then eval manually\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'training_input_fn' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "9jFVovcUUVs1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualize predictions"
      ]
    },
    {
      "metadata": {
        "id": "w12OId8Mz7dF",
        "colab_type": "code",
        "outputId": "5415f8d5-8beb-4a1e-c2cc-2f6b29cba694",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2343
        }
      },
      "cell_type": "code",
      "source": [
        "# recognize digits from local fonts\n",
        "# TPU REFACTORING: TPUEstimator.predict requires a 'params' in ints input_fn so that it can pass params['batch_size']\n",
        "#predictions = estimator.predict(lambda:  tf.data.Dataset.from_tensor_slices(font_digits).batch(N),\n",
        "predictions = estimator.predict(lambda params:  tf.data.Dataset.from_tensor_slices(font_digits).batch(N),\n",
        "                                  yield_single_examples=False)  # the returned value is a generator that will yield one batch of predictions per next() call\n",
        "predicted_font_classes = next(predictions)['classes']\n",
        "display_digits(font_digits, predicted_font_classes, font_labels, \"predictions from local fonts (bad predictions in red)\", N)\n",
        "\n",
        "# recognize validation digits\n",
        "predictions = estimator.predict(validation_input_fn,\n",
        "                                yield_single_examples=False)  # the returned value is a generator that will yield one batch of predictions per next() call\n",
        "predicted_labels = next(predictions)['classes']\n",
        "display_top_unrecognized(validation_digits, predicted_labels, validation_labels, N, 7)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:InvalidArgumentError: GCS path doesn't contain a bucket name: gs:///mnistjobs/job-2019-03-20-07:31:47/checkpoint\n",
            "WARNING:tensorflow:gs:///mnistjobs/job-2019-03-20-07:31:47/checkpoint: Checkpoint ignored\n",
            "INFO:tensorflow:Could not find trained model in model_dir: gs:///mnistjobs/job-2019-03-20-07:31:47, running initialization to predict.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.94.251.122:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 17709483334174943500)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 12038735802649731452)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 14990054698208882944)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 13471511649138046161)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 12867296683689994175)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7917374497578629146)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 7191505823400386747)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 9087626606891706482)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 4044324350022886599)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 5320281346217239334)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 6151300917863780659)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Error recorded from prediction_loop: name 'font_digits' is not defined\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "WARNING:tensorflow:Reraising captured error\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-49812c92890f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m predictions = estimator.predict(lambda params:  tf.data.Dataset.from_tensor_slices(font_digits).batch(N),\n\u001b[1;32m      2\u001b[0m                                   yield_single_examples=False)  # the returned value is a generator that will yield one batch of predictions per next() call\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredicted_font_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdisplay_digits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont_digits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_font_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfont_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"predictions from local fonts (bad predictions in red)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[1;32m   2498\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2499\u001b[0m       \u001b[0mrendezvous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prediction_loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2500\u001b[0;31m       \u001b[0mrendezvous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2502\u001b[0m     \u001b[0mrendezvous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prediction_loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/error_handling.py\u001b[0m in \u001b[0;36mraise_errors\u001b[0;34m(self, timeout_sec)\u001b[0m\n\u001b[1;32m    126\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reraising captured error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkept_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[1;32m   2492\u001b[0m           \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2493\u001b[0m           \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2494\u001b[0;31m           yield_single_examples=yield_single_examples):\n\u001b[0m\u001b[1;32m   2495\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2496\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[1;32m    609\u001b[0m             input_fn, model_fn_lib.ModeKeys.PREDICT)\n\u001b[1;32m    610\u001b[0m         estimator_spec = self._call_model_fn(\n\u001b[0;32m--> 611\u001b[0;31m             features, None, model_fn_lib.ModeKeys.PREDICT, self.config)\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;31m# Call to warm_start has to be after model_fn is called.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   2249\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2250\u001b[0m       return super(TPUEstimator, self)._call_model_fn(features, labels, mode,\n\u001b[0;32m-> 2251\u001b[0;31m                                                       config)\n\u001b[0m\u001b[1;32m   2252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2253\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_model_fn_for_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36m_model_fn\u001b[0;34m(features, labels, mode, config, params)\u001b[0m\n\u001b[1;32m   2545\u001b[0m         \u001b[0minput_holders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_InputPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2546\u001b[0m         enqueue_ops, dequeue_fn, input_hooks, run_infeed_loop_on_coordinator = (\n\u001b[0;32m-> 2547\u001b[0;31m             input_holders.generate_infeed_enqueue_ops_and_dequeue_fn())\n\u001b[0m\u001b[1;32m   2548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2549\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36mgenerate_infeed_enqueue_ops_and_dequeue_fn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     \u001b[0;31m# structure is recorded.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m     enqueue_ops, all_hooks, run_infeed_loop_on_coordinator = (\n\u001b[0;32m-> 1167\u001b[0;31m         self._invoke_input_fn_and_record_structure())\n\u001b[0m\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36m_invoke_input_fn_and_record_structure\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1247\u001b[0m                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inputs_structure_recorder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m                       host_device, host_id))\n\u001b[0m\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m             \u001b[0;31m# NOTE(xiejw): We dispatch here based on the return type of the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36mgenerate_per_host_enqueue_ops_fn_for_host\u001b[0;34m(ctx, input_fn, inputs_structure_recorder, batch_axis, device, host_id)\u001b[0m\n\u001b[1;32m    754\u001b[0m     user_context = tpu_context.TPUContext(\n\u001b[1;32m    755\u001b[0m         internal_ctx=ctx, input_device=device, invocation_index=host_id)\n\u001b[0;32m--> 756\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[0mis_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36m_input_fn\u001b[0;34m(ctx)\u001b[0m\n\u001b[1;32m   2421\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0m_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m         \u001b[0m_add_item_to_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_CTX_KEY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2425\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_input_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-49812c92890f>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(params)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m predictions = estimator.predict(lambda params:  tf.data.Dataset.from_tensor_slices(font_digits).batch(N),\n\u001b[0m\u001b[1;32m      2\u001b[0m                                   yield_single_examples=False)  # the returned value is a generator that will yield one batch of predictions per next() call\n\u001b[1;32m      3\u001b[0m \u001b[0mpredicted_font_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdisplay_digits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont_digits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_font_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfont_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"predictions from local fonts (bad predictions in red)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'font_digits' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "5tzVi39ShrEL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Deploy the trained model to ML Engine\n",
        "\n",
        "Push your trained model to production on ML Engine for a serverless, autoscaled, REST API experience.\n",
        "\n",
        "You will need a GCS bucket and a GCP project for this.\n",
        "Models deployed on ML Engine autoscale to zero if not used. There will be no ML Engine charges after you are done testing.\n",
        "Google Cloud Storage incurs charges. Empty the bucket after deployment if you want to avoid these. Once the model is deployed, the bucket is not useful anymore."
      ]
    },
    {
      "metadata": {
        "id": "3Y3ztMY_toCP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Configuration"
      ]
    },
    {
      "metadata": {
        "id": "iAZAn7yIhqAS",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "f249674c-8fea-4044-ad67-565183244526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "cell_type": "code",
      "source": [
        "PROJECT = \"\" #@param {type:\"string\"}\n",
        "NEW_MODEL = True #@param {type:\"boolean\"}\n",
        "MODEL_NAME = \"estimator_mnist_tpu\" #@param {type:\"string\"}\n",
        "MODEL_VERSION = \"v0\" #@param {type:\"string\"}\n",
        "\n",
        "assert PROJECT, 'For this part, you need a GCP project. Head to http://console.cloud.google.com/ and create one.'\n",
        "\n",
        "#TPU REFACTORING: TPUEstimator does not create the 'export' subfolder\n",
        "#export_path = os.path.join(MODEL_DIR, 'export', MODEL_EXPORT_NAME)\n",
        "export_path = os.path.join(MODEL_DIR, MODEL_EXPORT_NAME)\n",
        "last_export = sorted(tf.gfile.ListDirectory(export_path))[-1]\n",
        "export_path = os.path.join(export_path, last_export)\n",
        "print('Saved model directory found: ', export_path)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-3e472ecab3da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mMODEL_VERSION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"v0\"\u001b[0m \u001b[0;31m#@param {type:\"string\"}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mPROJECT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'For this part, you need a GCP project. Head to http://console.cloud.google.com/ and create one.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#TPU REFACTORING: TPUEstimator does not create the 'export' subfolder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: For this part, you need a GCP project. Head to http://console.cloud.google.com/ and create one."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "zy3T3zk0u2J0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Deploy the model\n",
        "This uses the command-line interface. You can do the same thing through the ML Engine UI at https://console.cloud.google.com/mlengine/models\n"
      ]
    },
    {
      "metadata": {
        "id": "nGv3ITiGLPL3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "3684de24-3cac-45b7-9134-0e36c2620512"
      },
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "if NEW_MODEL:\n",
        "  !gcloud ml-engine models create {MODEL_NAME} --project={PROJECT} --regions=us-central1"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;31mERROR:\u001b[0m (gcloud.ml-engine.models.create) The project property is set to the empty string, which is invalid.\n",
            "To set your project, run:\n",
            "\n",
            "  $ gcloud config set project PROJECT_ID\n",
            "\n",
            "or to unset it, run:\n",
            "\n",
            "  $ gcloud config unset project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o3QtUowtOAL-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "0e7f9ed9-0049-4690-d5a4-9d0e0071841c"
      },
      "cell_type": "code",
      "source": [
        "# Create a version of this model (you can add --async at the end of the line to make this call non blocking)\n",
        "# Additional config flags are available: https://cloud.google.com/ml-engine/reference/rest/v1/projects.models.versions\n",
        "# You can also deploy a model that is stored locally by providing a --staging-bucket=... parameter\n",
        "!echo \"Deployment takes a couple of minutes. You can watch your deployment here: https://console.cloud.google.com/mlengine/models/{MODEL_NAME}\"\n",
        "!gcloud ml-engine versions create {MODEL_VERSION} --model={MODEL_NAME} --origin={export_path} --project={PROJECT} --runtime-version=1.10"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Deployment takes a couple of minutes. You can watch your deployment here: https://console.cloud.google.com/mlengine/models/estimator_mnist_tpu\n",
            "\u001b[1;31mERROR:\u001b[0m (gcloud) The project property must be set to a valid project ID, [{PROJECT}] is not a valid project ID.\n",
            "To set your project, run:\n",
            "\n",
            "  $ gcloud config set project PROJECT_ID\n",
            "\n",
            "or to unset it, run:\n",
            "\n",
            "  $ gcloud config unset project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jE-k1Zn6kU2Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test the deployed model\n",
        "Your model is now available as a REST API. Let us try to call it. The cells below use the \"gcloud ml-engine\"\n",
        "command line tool but any tool that can send a JSON payload to a REST endpoint will work."
      ]
    },
    {
      "metadata": {
        "id": "zZCt0Ke2QDer",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "1cf17bab-cec0-4dd7-86b3-b45d97e1bfb7"
      },
      "cell_type": "code",
      "source": [
        "# prepare digits to send to online prediction endpoint\n",
        "digits = np.concatenate((font_digits, validation_digits[:100-N]))\n",
        "labels = np.concatenate((font_labels, validation_labels[:100-N]))\n",
        "with open(\"digits.json\", \"w\") as f:\n",
        "  for digit in digits:\n",
        "    # the format for ML Engine online predictions is: one JSON object per line\n",
        "    data = json.dumps({\"serving_input\": digit.tolist()})  # \"serving_input\" because that is what you defined in your serving_input_fn: {\"serving_input\": tf.placeholder(tf.float32, [None, 28, 28])}\n",
        "    f.write(data+'\\n')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-aad859b8438d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdigits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont_digits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_digits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"digits.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mdigit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# the format for ML Engine online predictions is: one JSON object per line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'font_digits' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "n6PqhQ8RQ8bp",
        "colab_type": "code",
        "outputId": "f29f9a92-1bf8-49b2-f01f-632fa1b841c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "cell_type": "code",
      "source": [
        "# Request online predictions from deployed model (REST API) using the \"gcloud ml-engine\" command line.\n",
        "predictions = !gcloud ml-engine predict --model={MODEL_NAME} --json-instances digits.json --project={PROJECT} --version {MODEL_VERSION}\n",
        "\n",
        "predictions = np.array([int(p.split('[')[0]) for p in predictions[1:]]) # first line is the name of the input layer: drop it, parse the rest\n",
        "display_top_unrecognized(digits, predictions, labels, N, 100//N)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-0e6023a13856>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'['\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# first line is the name of the input layer: drop it, parse the rest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdisplay_top_unrecognized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'digits' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "XXSk0bENYB7-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## License"
      ]
    },
    {
      "metadata": {
        "id": "hleIN5-pcr0N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "author: Martin Gorner<br>\n",
        "twitter: @martin_gorner\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Copyright 2018 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "This is not an official Google product but sample code provided for an educational purpose\n"
      ]
    }
  ]
}